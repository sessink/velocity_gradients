{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import bottleneck as bn\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "from scipy.special import comb\n",
    "from scipy.stats import circmean,circstd # circular statistics\n",
    "from sklearn.utils import resample # for bootstrapping\n",
    "from itertools import combinations\n",
    "from datetime import datetime,timedelta\n",
    "from nn_vorticity_module import least_square_method\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from haversine import haversine\n",
    "import random\n",
    "import matplotlib.dates as mdates\n",
    "import multiprocessing as mp\n",
    "from time import time\n",
    "import scipy.linalg as la\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set(style='whitegrid', context='poster', font_scale=1.2)\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polygon:\n",
    "    \n",
    "    def __init__(self,i,comb,data):\n",
    "        # initialize polygon\n",
    "        #self.id = i\n",
    "        #self.drifters=comb # indices of drifters in polygon\n",
    "        self.lats=data.lat.values\n",
    "        self.lons=data.lon.values\n",
    "        self.com=np.array( [bn.nanmean(data.lon.values),bn.nanmean(data.lat.values)])\n",
    "        #self.us=data.uv.real/100\n",
    "        #self.vs=data.uv.imag/100\n",
    "        self.length=[]\n",
    "        self.aspect=[]\n",
    "        self.angle=[]\n",
    "    \n",
    "    def p(self,i):\n",
    "        # return coordinates of a point\n",
    "        return [self.lons[i],self.lats[i]]\n",
    "    \n",
    "    def calc_lengths(self):\n",
    "        lengths=[]\n",
    "        ncc = len(self.lons)\n",
    "        r = combinations(np.arange(ncc), 2) \n",
    "        \n",
    "        k=0\n",
    "        for i,j in r:\n",
    "            lengths.append( haversine( self.p(i),self.p(j) ) )\n",
    "            k+=1\n",
    "            \n",
    "        lengths=np.array(lengths)                   \n",
    "        if np.sum(np.isfinite(lengths))==k:\n",
    "            self.length = np.sqrt( np.mean(lengths**2) )\n",
    "        else:\n",
    "            self.length = np.nan           \n",
    "    \n",
    "    def least_square_method(self):\n",
    "        #import gsw\n",
    "        import scipy.linalg as la\n",
    "        timeseries=True\n",
    "        ncc = len(self.lons)\n",
    "        dlon=[]\n",
    "        dlat=[] \n",
    "        for i in range(ncc):\n",
    "            # haversine(p1,p2)\n",
    "            dlon.append(haversine( [self.lons[i],self.com[1]],self.com)*1000*np.sign(self.lons[i]-self.com[0]))\n",
    "            dlat.append(haversine( [self.com[0],self.lats[i]],self.com)*1000*np.sign(self.lats[i]-self.com[1]))\n",
    "        \n",
    "        if not timeseries:\n",
    "            R = np.mat( np.vstack( (np.ones((ncc,)) ,np.array(dlon), np.array(dlat) )).T )\n",
    "            u0=np.mat(self.us).T\n",
    "            v0=np.mat(self.vs).T\n",
    "\n",
    "            A,_,_,_=la.lstsq(R,u0)\n",
    "            B,_,_,_=la.lstsq(R,v0)\n",
    "        \n",
    "            self.A=A[1:]\n",
    "            self.B=B[1:]\n",
    "\n",
    "        points =np.vstack( [dlon,dlat] )\n",
    "        if np.sum( np.isfinite(points))==2*npol:\n",
    "            # careful with nans\n",
    "            cov = np.cov(points)\n",
    "            w,v = np.linalg.eig(cov)\n",
    "            self.aspect = bn.nanmin(w)/bn.nanmax(w)\n",
    "            \n",
    "        else:\n",
    "            self.aspect=np.nan\n",
    "            #self.angle=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePolygons(i):\n",
    "    criteria2 = data_chosen.particle.isin(combs[i])\n",
    "    return Polygon(i,combs[i],data_chosen[criteria2])\n",
    "\n",
    "def calc_properties(i):\n",
    "    results[i].calc_lengths()\n",
    "    results[i].least_square_method() \n",
    "    return results[i]\n",
    "\n",
    "@jit\n",
    "def find_percentiles(data):\n",
    "    alpha = 0.75 # 95% confidence interval\n",
    "    ordered = np.sort(data)\n",
    "    lo = np.percentile(ordered,100*(1-alpha)/2,)\n",
    "    hi = np.percentile(ordered,100*(alpha+(1-alpha)/2))\n",
    "    return lo,hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sebastianessink/Dropbox (MIT)/deform/src/deformations'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=45, npol=3, Nnpol=14190, T=32\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../data/drifters/'\n",
    "data = pd.read_pickle(data_path+'/posveldata_all.pkl')\n",
    "N = data.particle.unique().size\n",
    "npol=3\n",
    "Nnpol = comb(N,npol,exact=True)\n",
    "sampling_times = pd.date_range(data.index.unique()[0], periods=32, freq='1D')\n",
    "T = len(sampling_times)\n",
    "print('N=%d, npol=%d, Nnpol=%d, T=%d' %(N,npol,Nnpol,T))\n",
    "\n",
    "combs=[]\n",
    "for combi in combinations(np.arange(N),npol):\n",
    "    combs.append(combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-09-03', '2015-09-04', '2015-09-05', '2015-09-06',\n",
       "               '2015-09-07', '2015-09-08', '2015-09-09', '2015-09-10',\n",
       "               '2015-09-11', '2015-09-12', '2015-09-13', '2015-09-14',\n",
       "               '2015-09-15', '2015-09-16', '2015-09-17', '2015-09-18',\n",
       "               '2015-09-19', '2015-09-20', '2015-09-21', '2015-09-22',\n",
       "               '2015-09-23', '2015-09-24', '2015-09-25', '2015-09-26',\n",
       "               '2015-09-27', '2015-09-28', '2015-09-29', '2015-09-30',\n",
       "               '2015-10-01', '2015-10-02', '2015-10-03', '2015-10-04'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 step in 0 0.049 minutes\n",
      "1 step in 4 0.269 minutes\n",
      "1 step in 8 0.518 minutes\n",
      "1 step in 12 0.746 minutes\n",
      "1 step in 16 0.975 minutes\n",
      "1 step in 20 1.194 minutes\n",
      "1 step in 24 1.423 minutes\n",
      "1 step in 28 1.642 minutes\n",
      "save data\n",
      "total 1.799 minutes\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "\n",
    "mean_length=np.zeros(T)\n",
    "median_length=np.zeros(T)\n",
    "std_length=np.zeros(T)\n",
    "lo_length=np.zeros(T)\n",
    "hi_length=np.zeros(T)\n",
    "\n",
    "median_aspect=np.zeros(T)\n",
    "mean_aspect=np.zeros(T)\n",
    "lo_aspect=np.zeros(T)\n",
    "hi_aspect=np.zeros(T)\n",
    "\n",
    "\n",
    "start = time()\n",
    "for t,tim in enumerate(sampling_times):\n",
    "    \n",
    "    results=[]\n",
    "    if tim in data.index:\n",
    "              \n",
    "        # select subset in time\n",
    "        data_chosen = data[data.index == tim]\n",
    "        \n",
    "        # make polygons\n",
    "        results=[]\n",
    "        pool = mp.Pool(8)     \n",
    "        results = pool.map(makePolygons, range(Nnpol))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        # calculate properties\n",
    "        pool = mp.Pool(8)     \n",
    "        results = pool.map(calc_properties, range(Nnpol))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        # read geometry data\n",
    "        asp = np.array([results[i].aspect for i in range(Nnpol)]).squeeze()\n",
    "        ang = np.array([results[i].angle for i in range(Nnpol)]).squeeze()\n",
    "        leng = np.array([results[i].length for i in range(Nnpol)]).squeeze()\n",
    "        \n",
    "        mean_length[t] = bn.nanmean(leng)\n",
    "        std_length[t] = bn.nanstd(leng)\n",
    "        median_length[t] = bn.nanmedian(leng)\n",
    "        lo_length[t],hi_length[t] = find_percentiles(leng[np.isfinite(leng)])\n",
    "        \n",
    "        mean_aspect[t] = bn.nanmean(asp)\n",
    "        median_aspect[t] = bn.nanmedian(asp)\n",
    "        lo_aspect[t],hi_aspect[t] = find_percentiles(asp[np.isfinite(asp)])\n",
    "        \n",
    "        if np.mod(t,4)==0:\n",
    "            print('1 step in %d %3.3f minutes' %(t,(time()-start)/60) )\n",
    "        \n",
    "    else:\n",
    "        print('no data at that time.')\n",
    "        \n",
    "print('save data' )\n",
    "df=[]\n",
    "df = pd.DataFrame(index=sampling_times,data={'mean_length':mean_length,'median_length':median_length,'lo_length':lo_length,'hi_length':hi_length,\n",
    "                                     'mean_aspect':mean_aspect,'median_aspect':median_aspect,'lo_aspect':lo_aspect,'hi_aspect':hi_aspect})\n",
    "\n",
    "df['dtime']=df.index-df.index[0]\n",
    "df['dtime']=df.dtime.dt.days.values\n",
    "fname = 'deformation_n_6_T_90d_split_%d.pkl' %t\n",
    "df.to_pickle(data_path+fname)\n",
    "    \n",
    "print('total %3.3f minutes' %((time()-start)/60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
