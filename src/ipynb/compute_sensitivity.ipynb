{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scientific Computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "\n",
    "import bottleneck as bn\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tools.tools import *\n",
    "from tools.io import *\n",
    "from tools.methods import *\n",
    "\n",
    "sns.set(context='talk', style='whitegrid', font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_length(N, filt, fu, fv, fzeta):\n",
    "    '''\n",
    "    least square method varying length of hexagons\n",
    "    '''\n",
    "    M = 3\n",
    "    llist = np.arange(1, 30, 1).astype(float)\n",
    "    llist = np.insert(llist, 0, 0.5)\n",
    "    skew=1\n",
    "    \n",
    "    error = []\n",
    "    error_l = []\n",
    "    error3 = []\n",
    "    error_l_ci = []\n",
    "    for l, L in enumerate(llist):\n",
    "        # make polygons\n",
    "        xi, yi = make_n_hexs(L, skew, N, M)\n",
    "\n",
    "        # find the u,v at the polygon vertices\n",
    "        ui = fu.ev(xi, yi)\n",
    "        vi = fu.ev(xi, yi)\n",
    "        # find zeta at polygon center\n",
    "        true1 = fzeta.ev(bn.nanmean(xi, axis=1), bn.nanmean(yi, axis=1))\n",
    "        true2 = np.nanmean( fzeta.ev(xi, yi), axis=1)\n",
    "\n",
    "        estimate = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            estimate[i], _, _ = least_square_method(\n",
    "                xi[i, :], yi[i, :], ui[i, :], vi[i, :], 'solve')\n",
    "        \n",
    "        # compute R2 and confidence interval\n",
    "        error.append(stats.pearsonr(true2, estimate)[0]**2)\n",
    "        error_l.append(stats.pearsonr(true1, estimate)[0]**2)\n",
    "        error_l_ci.append(bootstrap_ci(true1, estimate, N))\n",
    "        error3.append( np.nanmean( (estimate-true1)/true1 ) )\n",
    "\n",
    "    # save in dataframe\n",
    "    df = pd.DataFrame(index=np.asarray(llist))\n",
    "    df['error1'] = np.asarray(error)\n",
    "    df['error2'] = np.asarray(error_l)\n",
    "    df['error3'] = np.asarray(error3)\n",
    "    df['ci_low'] = np.asarray(error_l_ci)[:, 0]\n",
    "    df['ci_high'] = np.asarray(error_l_ci)[:, 1]\n",
    "    df['filter'] = filt\n",
    "\n",
    "    return df\n",
    "\n",
    "def sensitivity_aspect(N, filt, fu, fv, fzeta):\n",
    "    '''\n",
    "    least square method varying number of drifter per cluster\n",
    "    '''\n",
    "    L = 2\n",
    "    M = 3\n",
    "    skewlist = np.arange(1, 30, 1)\n",
    "\n",
    "    aspect = []\n",
    "    error = []\n",
    "    error3 = []\n",
    "    error_l = []\n",
    "    error_l_ci = []\n",
    "    for l, skew in enumerate(skewlist):\n",
    "        # make polygons\n",
    "        xi, yi = make_n_hexs(L, skew, N, M)\n",
    "\n",
    "        # find the u,v at the polygon vertices\n",
    "        ui = fu.ev(xi, yi)\n",
    "        vi = fv.ev(xi, yi)\n",
    "        # find zeta at polygon center\n",
    "        true1 = fzeta.ev(bn.nanmean(xi, axis=1), bn.nanmean(yi, axis=1))\n",
    "        true2 = np.nanmean( fzeta.ev(xi, yi), axis=1)\n",
    "\n",
    "        estimate = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            estimate[i], _, _ = least_square_method(\n",
    "                xi[i, :], yi[i, :], ui[i, :], vi[i, :], 'lstsq')\n",
    "\n",
    "        # compute aspect ratio, R2 and confidence interval\n",
    "        aspect.append(calc_aspect(xi[0, :], yi[0, :]))\n",
    "        error.append(stats.pearsonr(true2, estimate)[0]**2)\n",
    "        error_l.append(stats.pearsonr(true1, estimate)[0]**2)\n",
    "        error_l_ci.append(bootstrap_ci(true1, estimate, N))\n",
    "        error3.append( np.nanmean( (estimate-true1)/true1 ) )\n",
    "    \n",
    "    # save in dataframe\n",
    "    df = pd.DataFrame(index=np.asarray(aspect))\n",
    "    df['error1'] = np.asarray(error)\n",
    "    df['error2'] = np.asarray(error_l)\n",
    "    df['error3'] = np.asarray(error3)\n",
    "    df['ci_low'] = np.asarray(error_l_ci)[:, 0]\n",
    "    df['ci_high'] = np.asarray(error_l_ci)[:, 1]\n",
    "    df['filter'] = filt\n",
    "\n",
    "    return df\n",
    "\n",
    "def sensitivity_number(N, filt, fu, fv, fzeta):\n",
    "    '''\n",
    "    least square method varying number of drifter per cluster\n",
    "    '''\n",
    "    L = 10\n",
    "    mlist = np.arange(3, 21)\n",
    "    skew=1\n",
    "    \n",
    "    error = []\n",
    "    error3 = []\n",
    "    error_l = []\n",
    "    error_l_ci = []\n",
    "    for l, M in enumerate(mlist):\n",
    "        # make polygons\n",
    "        xi, yi = make_n_hexs(L, skew, N, M)\n",
    "\n",
    "        # find the u,v at the polygon vertices\n",
    "        ui = fu.ev(xi, yi)\n",
    "        vi = fv.ev(xi, yi)\n",
    "        # find zeta at polygon center\n",
    "        true1 = fzeta.ev(bn.nanmean(xi, axis=1), bn.nanmean(yi, axis=1))\n",
    "        true2 = np.nanmean( fzeta.ev(xi, yi), axis=1)\n",
    "\n",
    "        # estimate vorticity from the velocities\n",
    "        estimate = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            estimate[i], _, _ = least_square_method(\n",
    "                xi[i, :], yi[i, :], ui[i, :], vi[i, :], 'inv')\n",
    "        \n",
    "        # compute R2 and confidence interval\n",
    "        error3.append( np.nanmean( (estimate-true1)/true1 ) )\n",
    "        error.append(stats.pearsonr(true2, estimate)[0]**2)\n",
    "        error_l.append(stats.pearsonr(true1, estimate)[0]**2)\n",
    "        error_l_ci.append(bootstrap_ci(true1, estimate, N))\n",
    "\n",
    "    # save in dataframe\n",
    "    df = pd.DataFrame(index=np.asarray(mlist))\n",
    "    df['error1'] = np.asarray(error)\n",
    "    df['error2'] = np.asarray(error_l)\n",
    "    df['error3'] = np.asarray(error3)\n",
    "    df['ci_low'] = np.asarray(error_l_ci)[:, 0]\n",
    "    df['ci_high'] = np.asarray(error_l_ci)[:, 1]\n",
    "    df['filter'] = filt\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% MAIN\n",
    "data_path = '../../data/'\n",
    "zgrid_path = data_path+'psom/zgrid.out'\n",
    "model_path = data_path+'psom/full_08325.cdf'\n",
    "\n",
    "# dat = read_model_field(snakemake.input[0], snakemake.input[1])\n",
    "dat = read_model_field(zgrid_path, model_path) \n",
    "dat = dat.rename({'xc':'x'})\n",
    "dat = dat.rename({'yc':'y'})\n",
    "dat = dat.set_coords({'x','y'})\n",
    "dat = dat.transpose('x','y')\n",
    "\n",
    "fu, fv, fzeta = filter_fields(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "\n",
    "length_bucket = []\n",
    "number_bucket = []\n",
    "aspect_bucket = []\n",
    "for i, filt in enumerate([0, 10, 20]):\n",
    "    print(filt)\n",
    "    length_bucket.append(\n",
    "        sensitivity_length(N, filt, fu=fu[i], fv=fv[i], fzeta=fzeta[i]))\n",
    "    number_bucket.append(\n",
    "        sensitivity_number(N, filt, fu=fu[i], fv=fv[i], fzeta=fzeta[i]))\n",
    "    aspect_bucket.append(\n",
    "        sensitivity_aspect(N, filt, fu=fu[i], fv=fv[i], fzeta=fzeta[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(length_bucket).reset_index().to_feather(data_path+'psom/sensitivity_length.feather')\n",
    "pd.concat(number_bucket).reset_index().to_feather(data_path+'psom/sensitivity_number.feather')\n",
    "pd.concat(aspect_bucket).reset_index().to_feather(data_path+'psom/sensitivity_aspect.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
